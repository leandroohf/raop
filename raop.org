

* Introduction

  Eu vou basear bem no Rpub
  http://www.runzemc.com/2014/08/random-acts-of-pizza.html
  https://rpubs.com/kuhnrl30/RAOP

  * Explain waht is RAoP
  * Discuss a little about article reference
  * Discuss what we decided to do n why
    
* Data

  * Explain what I did in descriptive

    We select the variable in the target data frame below for the
    exploratory analysis
    
  ================================= Importante

  Explicar pq converti para Decile e pq nao considerei valores negativos
  E o motivo foi que para narrative score, muitas narrativas nao pontua gerando 
  uma concentracao no em zero e assim gera discontinidade na distribuicao dos scores
  Ex: 1000 posts com 0 decile e depois 7 decile com 100, 8 com 200 3 assim eu tenho
  a dist do restante dos potnos. 


  ## So zero freq in narrative score are represented as 0 decile
  ## Also affect negative sentiment score but It seems 

    
  #+BEGIN_SRC R :session :tangle raop.R :results none
    ##* ****************************************************************
    ##  Programmer[s]: Leandro Fernandes
    ##  Company/Institution:
    ##  email: leandroohf@gmail.com
    ##  Date: June 20, 2016
    ##  
    ##  The author believes that share code and knowledge is awesome.
    ##  Feel free to share and modify this piece of code. But don't be
    ##  impolite and remember to cite the author and give him his credits.
    ##* ****************************************************************

    library(jsonlite, quietly = TRUE )
    library(feather, quietly = TRUE )
    library(ggplot2, quietly = TRUE )
    library(grid)
    library(gridExtra)
    library(ggthemes)

    source("./utils/data.R")
    source("./utils/utils.R")

    settings   <- fromJSON( "SETTINGS.json", flatten=TRUE)

    cat('Loading data engineer...\n')
    raop.engineer <- readRDS(settings$data_engineer_path)

    data.target <- raop.engineer$GetDataTarget()
  #+END_SRC

* Exploratory

  plot graphs that I found on Rpubs
  
  #+BEGIN_SRC R :session :tangle exp.R
    data.view <- data.target %>%
        dplyr::group_by( requester_upvotes_minus_downvotes_at_request ) %>%
        dplyr::summarise(  success_rate = sum( requester_received_pizza )/ n(),
                         account_age = mean(requester_account_age_in_days_at_request))

    names(data.view)[1] <- c("karma")
    p.karma <- ggplot(data.view, aes(x=karma,y=success_rate)) + geom_line()

    ## =================================
    ## account age
    p.account.age <- ggplot(data.view, aes(x=account_age,y=success_rate)) + geom_line()

    ## =================================
    ## community age
    data.view <- data.target %>%
        dplyr::group_by( community_age ) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("community_age")
    p.community.age <- ggplot(data.view, aes(x=community_age,y=success_rate)) + geom_line()

    grid.arrange(p.karma, p.account.age, p.community.age, ncol = 3)

  #+END_SRC
  
  *Um pto que fiz diferente* Entao eu devo colocar separado.
  
  #+BEGIN_SRC R :session :tangle exp.R
    ## =================================
    ## post sent
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( post.sent) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("post_sent")
    p <- ggplot(data.view, aes(x=post_sent,y=success_rate)) + geom_line()
    p

    ## =================================
    ## narrative score
    cols.narratives <- c("desire.score",
                         "family.score",
                         "job.score",
                         "money.score",
                         "student.score")

    data.view0 <- data.target %>%
        dplyr::select( dplyr::one_of( c(cols.narratives,
                                        "requester_received_pizza")))

    data.view <- data.frame(decile=integer(),
                            success_rate=double(),
                            narrative=character())

    for ( narrative in cols.narratives){
    
        narrative.view <- data.view0 %>%
            na.omit() %>%
            dplyr::group_by_( narrative ) %>%
            dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())  %>%
            dplyr::mutate(narrative)
    
        names(narrative.view)[1] <- "decile" 
    
        data.view <- rbind(data.view, narrative.view)
    }

    p <- ggplot(data.view, aes(x = decile, y = success_rate, colour = narrative, group = narrative)) +
        geom_line() + ggtitle('Success rate vs. narrative') +
        scale_x_continuous(breaks = seq(0, 10, 1), name = 'Narrative declie') +
        scale_y_continuous(name = 'Success rate')

    p

  #+END_SRC

  #+BEGIN_SRC R :session :tangle exp.R
    ## =================================
    ## first half of the month 
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( first.half.of.month ) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("first_half")
    p <- ggplot(data.view, aes(x=first_half,y=success_rate)) + geom_bar(stat = 'identity')

    summary(aov(  requester_received_pizza ~ first.half.of.month, data.target ))

    ## =================================
    ## is weekend
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( is.weekend ) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("is_weekend")
    p <- ggplot(data.view, aes(x=is_weekend,y=success_rate)) + geom_bar(stat = 'identity')

    ## =================================
    ## month
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( lubridate::month(request.date)) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("month")
    p <- ggplot(data.view, aes(x=month,y=success_rate)) + geom_bar(stat = 'identity')

    ## =================================
    ## month day
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( lubridate::mday(request.date)) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("month_day")
    p <- ggplot(data.view, aes(x=month_day,y=success_rate)) + geom_bar(stat = 'identity')

    ## =================================
    ## week day
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( lubridate::wday(request.date)) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("week_day")
    p <- ggplot(data.view, aes(x=week_day,y=success_rate)) + geom_bar(stat = 'identity')
    print(p)

    ## =================================
    ## has posted before
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( posted.raop.before) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("posted_before")
    p <- ggplot(data.view, aes(x=posted_before,y=success_rate)) + geom_bar(stat = 'identity') 
    print(p)

    summary(aov(requester_received_pizza ~ posted.raop.before , data.target)) 

    ## =================================
    ## has link
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( has.link) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("has_link")
    p <- ggplot(data.view, aes(x=has_link,y=success_rate)) + geom_bar(stat = 'identity') 
    print(p)

    summary(aov(requester_received_pizza ~ has.link , data.target)) 

    ## =================================
    ## gratitude
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( gratitude) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("gratitude")
    p <- ggplot(data.view, aes(x=gratitude,y=success_rate)) + geom_bar(stat = 'identity') 
    print(p)

    summary(aov(requester_received_pizza ~ gratitude , data.target)) 

    ## =================================
    ## reciprocity
    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( reciprocity) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("reciprocity")
    p <- ggplot(data.view, aes(x=reciprocity,y=success_rate)) + geom_bar(stat = 'identity') 
    print(p)

    summary(aov(requester_received_pizza ~ reciprocity , data.target)) 

    ## =================================
    ## nword

    p <- ggplot(data.target, aes(x=requester_received_pizza,y=nword)) +
        geom_boxplot()
    print(p)

    p <- ggplot(data.target, aes(x=nword,)) +
        geom_histogram(binwidth = 1) + facet_grid(requester_received_pizza ~ . )
    print(p)

    summary(aov(requester_received_pizza ~ reciprocity , data.target)) 

    data.view <- data.target %>%
        na.omit() %>%
        dplyr::group_by( nword) %>%
        dplyr::summarise( success_rate = sum( requester_received_pizza )/ n())

    names(data.view)[1] <- c("nword")
    p <- ggplot(data.view, aes(x=nword,y=success_rate)) + geom_line()
    print(p)    
  #+END_SRC

* Model
** Development
   Add model creation code and some comments

   glm: 5 min; 6 cores: 1. second
   gbm: 30 min; 6 cores: 1.7 min
   rf: 30 min; 6 cores: 6.3 min; 7 cores: 6.0 min
   nnet: 4 min; 6 cores: 0.87 min

   O ganho com 7 nao eh muito mas a maquina ainda fica utilizavel
   enquanto eu rodo os experimentos

*** Data design (train, test n ensenble dataset)

    #+begin_src R
      library(caret)
      ##library(plyr)
      library(ggplot2)
      library(gridExtra)
      library(pROC)
      library(tictoc)

      library(doMC)
      registerDoMC(cores = 7)

      library(feather, quietly = TRUE )
      library(jsonlite, quietly = TRUE )
      source("./utils/data.R")
      source("./utils/utils.R")
      source("./utils/report.R")
      source("./utils/model.R")

      settings   <- fromJSON( "SETTINGS.json", flatten=TRUE)

      cat('Loading data engineer...\n')
      raop.engineer <- readRDS(settings$data_engineer_path)

      data.target <- raop.engineer$GetDataTarget()


      ## ----------------------------------- [ Data processing ]
      data.target <- data.target[, c("requester_upvotes_minus_downvotes_at_request",
                                 "nword",
                                 "requester_account_age_in_days_at_request",
                                 "requester_days_since_first_post_on_raop_at_request",
                                 "requester_number_of_posts_at_request",
                                 "requester_number_of_posts_on_raop_at_request",
                                 "money.score",
                                 "desire.score",
                                 "family.score",
                                 "job.score",
                                 "student.score",
                                 "post.sent",
                                 "has.link",
                                 "gratitude",
                                 "reciprocity",
                                 "is.weekend",
                                 "community_age",
                                 "first.half.of.month",
                                 "posted.raop.before",                           
                                 "requester_received_pizza")]

      data.target$has.link <- as.numeric(data.target$has.link)
      data.target$first.half.of.month <- as.numeric(data.target$first.half.of.month)
      data.target$posted.raop.before <- as.numeric(data.target$posted.raop.before)
      data.target$gratitude <- as.numeric(data.target$gratitude)
      data.target$reciprocity <- as.numeric(data.target$reciprocity)
      data.target$is.weekend <- as.numeric(data.target$is.weekend)

      data.target$requester_received_pizza <- as.factor(data.target$requester_received_pizza)
      levels(data.target$requester_received_pizza) <- list("fail" = FALSE, "success" = TRUE)

      set.seed(2014)
      train_ind = createDataPartition(data.target$requester_received_pizza,
                                     p = .80, list = FALSE)

      train_te = data.target[-train_ind, ]    # 20% test

      train_m = data.target[train_ind, ]  # 80% for models

      set.seed(2014)
      train_ind = createDataPartition(train_m$requester_received_pizza,
                                     p = .90, list = FALSE)

      train_tr = train_m[train_ind,]  ## 50% to train each model
      train_es = train_m[-train_ind,] ## 50% to train ensemble model 

      ## train the training set

      labelName    <- "requester_received_pizza"  
      ind_vars <- names(train_tr)[names(train_tr) != labelName ]

      cat(dim(train_te))
      cat(dim(train_tr))
      cat(dim(train_es))

      ctrl = trainControl(method = 'cv', summaryFunction = twoClassSummary, classProbs = T)
    #+end_src

*** DONE Logistic Regredssion

    Meu melhor modelo e aparentemente melhor do que o blog que esu
    estava seguindo e com bem menos variaveis com AUC maios

    AUC: 0.675 vs 0.669 (paper) vs 0.664 (blog)

    #+begin_src R

      ## ------------------------------- [ Logistic Regression ]
      set.seed(2014)
      tic("Training: GLM .....")
      logit_m <- train(requester_received_pizza ~
                          requester_upvotes_minus_downvotes_at_request +
                          community_age +
                          nword + has.link + post.sent + posted.raop.before +
                          reciprocity + 
                          family.score + student.score,
                      data = train_tr,
                      method = 'glm', metric = 'ROC', trControl = ctrl)

      logit_imp = varImp(logit_m)
      toc()

   #+end_src

*** DONE GBM

    +*TODO* (Unica coisa q pode explicar o rsultado anterior. senao der desiste)+
    Vou adicionar a dummy>money.score: money.score > 4 => 1
    
    +*TODO*  Se o anterior funcionar tentar+ Nao vou tentar
    desire.money < 3 => 1
    desire.money >=3 and < 8 => 2
    desire.money >= 8 => 3
    
    *Por incrivel que pareca piorou a situacao*
    
    Como eu melhore este resultado? Preciso fazer os graficos de tunning do caret

    http://topepo.github.io/caret/model-training-and-tuning.html
    
    pergunto se eu fizer scale n center (standardize vars) vou ter um melhor resultado?
    http://machinelearningmastery.com/pre-process-your-dataset-in-r/


    Sem preprocessing o melhor que eu consegui foi

    shrinkage: 0.005; ntree: 1500; depth: 4; auc: 0.75; time: ~2.0 minutos
    [[file:scratch/gbm_shr0.005_ntree1500_depth4_auc0.75.png]]

    ---------------------------------
    Nao consegui reproduzir resultado anterior e aprentemente nehuma
    transformacs de cente e scale ajudou a melhorar o resultado

    shrinkage: 0.005; ntree: 800; depth: 7; auc: 0.693; time: ~1.0 minutos
    [[file:scratch/gbm_shr0.005_ntree800_depth7_auc0.693.png]]


   #+begin_src R

     ## ----------------------------------------------- [ GBM ]
     gbm_tune = expand.grid( interaction.depth = c( 4,5, 6,7,8),
                            n.trees = c(400,500, 600, 700, 800, 900, 1000, 1100,1200, 1500, 2000),
                            shrinkage = c(.005),
                            n.minobsinnode = 9)

     set.seed(2014)
     tic("Training: GBM .....")
     gbm_m = train(x = train_tr[, ind_vars], y = train_tr$requester_received_pizza,
                   method = 'gbm', tuneGrid = gbm_tune,
                   metric = 'ROC', verbose = F, trControl = ctrl)

     #gbm_imp = varImp(gbm_m)
     toc()

   #+end_src


   #+begin_src R

     preprocess_params <- preProcess(train_tr, method=c("center", "scale"))
     train_tr_pre <- predict(preprocess_params, train_tr )

     ## Restoring defalts boolen variables value
     train_tr_pre[,"has.link"]                  <-  train_tr[,"has.link"]
     train_tr_pre[,"gratitude"]                 <-  train_tr[,"gratitude"]
     train_tr_pre[,"reciprocity"]               <-  train_tr[,"reciprocity"]
     train_tr_pre[,"is.weekend"]                <-  train_tr[,"is.weekend"]
     train_tr_pre[,"first.half.of.month"]       <-  train_tr[,"first.half.of.month"]
     train_tr_pre[,"posted.raop.before"]        <-  train_tr[,"posted.raop.before"]
     train_tr_pre[,"requester_received_pizza" ] <-  train_tr[,"requester_received_pizza" ]

     ## ----------------------------------------------- [ GBM ]
     gbm_tune = expand.grid( interaction.depth = c(2, 3, 4),
                            n.trees = c(500, 1000, 1500, 2000, 2500, 3000),
                            shrinkage = c(.001, .005),
                            n.minobsinnode = 9)

     set.seed(2014)
     tic("Training: GBM .....")
     gbm_m = train(x = train_tr_pre[, ind_vars], y = train_tr_pre$requester_received_pizza,
                   method = 'gbm', tuneGrid = gbm_tune,
                   metric = 'ROC', verbose = F, trControl = ctrl)

     #gbm_imp = varImp(gbm_m)
     toc()

   #+end_src

*** DONE Random Fodrest
    
    | mtry | ntree |    AUC | comm                                         |
    |------+-------+--------+----------------------------------------------|
    |    3 |   300 |  0.675 |                                              |
    |    2 |  1000 |  0.676 |                                              |
    |    2 |  1500 | 0.6759 |                                              |
    |    2 |  1750 | 0.6761 |                                              |
    |    2 |  2000 |  0.678 | best                                         |
    |    2 |  2250 |  0.675 |                                              |
    |    2 |  2500 |  0.676 |                                              |
    |    3 |  3000 |  0.676 | pouco melhor do q 2; 3000 no mesmo graficoxs |
    |      |  4500 |        |                                              |
    |------+-------+--------+----------------------------------------------|

    =================================
    [2017-01-22 Sun]
    dim(train_r):  4085   21
    
    mtry: 3; ntree: 2250; auc: 0.680
    
    =================================

   #+begin_src R
     ## ------------------------------------- [ Random Forest ]
     #random forests (mtry = 2, roc = .656)
     rf_tune = expand.grid(.mtry =  seq(2,5,1))

     set.seed(2014)
     tic("Training: RF .....")
     rf_m = train(x = train_tr[, ind_vars], y = train_tr$requester_received_pizza,
                  method = 'rf', ntree = 2250, metric = 'ROC', 
                  tuneGrid = rf_tune, trControl = ctrl, importance = T)

     #rf_imp = varImp(rf_m)
     toc()
   #+end_src

*** DONE Neura Network

    Eh provavel que nnet seja o mais sensivel ao sample size
    
    [2017-01-22 Sun]
    dim(train_r):  4085   21
    decay3; size4; auc0.679
    
    [[file:scratch/2017-01-22-nnet-decay3-size4-auc0.693.png]]
    
    =================================

   #+begin_src R
     ## ------------------------------------ [ Neural Network ]
     #nnet (size = 4, decay = 2, roc = .669)
     nnet_tune = expand.grid(size = seq(1,10,1), decay = c(2,3,4))

     set.seed(2014)
     tic("Training: Neural Net .....")
     nnet_m = train(x = train_tr[, ind_vars], y = train_tr$requester_received_pizza,
                    method = 'nnet',maxit = 1000, tuneGrid = nnet_tune,
                    metric = 'ROC', preProc = c('center', 'scale'),
                    verbose = F,
                    trControl = ctrl)

     nnet_imp = varImp(nnet_m)
     toc()

   #+end_src

*** DONE SVM

   [2017-01-22 Sun]
    dim(train_r):  4085   21


    Peerformnace muita baixa comparadao aos outros modelos.
    Acho que nao vale apena tunar

   #+begin_src R
      ## ----------------------------------------------- [ SVM ]

      # Use the expand.grid to specify the search space	
      svm_tune  <- expand.grid(sigma = c(0.001, 0.01, .05),
                               C = c(0.5, 0.75, 0.9, 1, 1.1, 1.25))

      set.seed(2014)
      tic("Training: SVM .....")
      svm_m <- train( x = train_tr[ , ind_vars], y = train_tr$requester_received_pizza,
                     method = "svmRadial", tuneGrid = svm_tune,
                     metric = "ROC", preProc = c("center", "scale"),
                     verbose= F,
                     trControl = ctrl)


      svm_imp = varImp(svm_m)
      svm_imp$model <- "SVM"
      toc()
   #+end_src

*** Simple Model

   #+begin_src R
      ## --------------------------------- [ best simple model ]

      tic("Training: Simple Model .....")
      simple_m <- glm( requester_received_pizza ~ nword,# + community_age + requester_upvotes_minus_downvotes_at_request,
                      family=binomial(link='logit'),
                      data = train_tr)

      toc()

      simple_p <- predict(simple_m, list(nword = train_te$nword),type="response")
   #+end_src
   
*** Ensemble

   #+begin_src R

     ## --------------------------------- [ Ensemble Baggging ]
     ## combine results

     logit_p <- predict(logit_m, train_te[, ind_vars], type = 'prob')
     rf_p    <- predict(rf_m, train_te[, ind_vars], type = 'prob')
     gbm_p   <- predict(gbm_m, train_te[, ind_vars], type = 'prob')
     nnet_p  <- predict(nnet_m, train_te[, ind_vars], type = 'prob')
     #svm_p   <- predict(svm_m, train_te[, ind_vars], type = 'prob')   

     mean_p <- (logit_p$success + rf_p$success + gbm_p$success + nnet_p$success) / 4
     median_p <- apply(cbind(logit_p$success,rf_p$success,gbm_p$success,nnet_p$success),1,median)

     ## ----------------------------------- [ Ensemble Stack  ]

     train_te$logit_prob <-  predict(logit_m, train_te[, ind_vars], type = 'prob')$success
     train_te$rf_prob    <-  predict(rf_m, train_te[, ind_vars], type = 'prob')$success
     train_te$gbm_prob   <-  predict(gbm_m, train_te[, ind_vars],type ='prob')$success
     train_te$nnet_prob  <-  predict(nnet_m, train_te[, ind_vars], type = 'prob')$success
     #train_te$svm_prob   <-  predict(svm_m, train_te[, ind_vars], type = 'prob')

     train_es$logit_prob <- predict(logit_m, train_es[, ind_vars], type = 'prob')$success
     train_es$rf_prob    <- predict(rf_m, train_es[, ind_vars], type = 'prob')$success
     train_es$gbm_prob   <- predict(gbm_m, train_es[, ind_vars],type ='prob')$success
     train_es$nnet_prob  <- predict(nnet_m, train_es[, ind_vars], type = 'prob')$success
     #train_es$svm_prob   <- predict(svm_m, train_es[, ind_vars], type = 'prob')


     stack_tune = expand.grid( interaction.depth = seq(1, 5, 2),
                            n.trees = seq(500, 2000, 500),
                            shrinkage = c(.01, .1),
                            n.minobsinnode = 9)

     set.seed(2014)
     tic("Training: Ensemble GBM ....")

     stack_vars <- names(train_es)[names(train_es) != labelName ]
     stack_m  <- train(x = train_es[, stack_vars], y = train_es$requester_received_pizza,
                       method = 'gbm', tuneGrid = stack_tune,
                       metric = 'ROC', verbose = F, trControl = ctrl)


     stack_p   <- predict(stack_m, train_te[, stack_vars], type = 'prob')

   #+end_src
   
*** Comparing Models

    Mudar para proxima secao depois

   #+begin_src R
     ## ------------------------------- [ Plot Var Importance ]

     ## plot importance
     plot_imp <- function(x) {

         ## data hangler
         df = data.frame(x[[1]])
         names(df) = 'importance'
         df$variable = row.names(df)

         var_order = df$variable[order(df$importance)]
         df$variable = factor(df$variable, levels = var_order)

         p <- ggplot(df, aes(x = importance, y = variable)) +
             geom_segment(aes(yend = variable), xend = 0, colour = 'grey50') +
             geom_point(size = 3, colour = '#1d91c0') +
         ggtitle(x[[2]]) + theme_bw() + guides(fill = F)

         return(p)
     }

     p_logit_imp <- plot_imp(logit_imp)
     p_rf_imp    <- plot_imp(rf_imp)
     p_gbm_imp   <- plot_imp(gbm_imp)
     p_nnet_imp  <- plot_imp(nnet_imp)
     p_svm_imp   <- plot_imp(svm_imp)

     grid.arrange(p_logit_imp, p_rf_imp, p_gbm_imp, p_nnet_imp, p_svm_imp, top= 'Variable importance')

     ## ---------------------------------- [ Comparing models ]
     success  <- predict(simple_m, list(nword = train_te$nword),type="response")
     simple_p <- data.frame(fail= 1.0 - success, success=success)
     
     pfail  <- sum(train_tr$requester_received_pizza == 'fail')/nrow(train_tr)
     null_p <- data.frame(fail = rep(pfail, nrow(train_te)),
                          success = rep(1.0 - pfail, nrow(train_te)))

     roc(train_te$requester_received_pizza, null_p$success) # random model
     roc(train_te$requester_received_pizza, simple_p$success)
     roc(train_te$requester_received_pizza, mean_p)
     roc(train_te$requester_received_pizza, median_p)
     roc(train_te$requester_received_pizza, stack_p$success)

     ## --------------------------------------- [ Preditcions ]

     pred_log  <- predict( object = logit_m, newdata = train_te, type = "prob")
     pred_gbm  <- predict( object = gbm_m, newdata = train_te[, ind_vars], type = "prob") 
     pred_rf   <- predict( object = rf_m, newdata = train_te, type = "prob")
     pred_nnet <- predict( object = nnet_m, newdata = train_te, type = "prob")
     ## pred_svm  <- predict( object = svm_m, newdata = train_te, type = "raw")

     pred_mean <- as.factor(mean_p > 0.5)
     levels(pred_mean) = list("fail" = FALSE, "success" = TRUE)

     ## pred_stacking <- gbm(Y ~ X:M1,M2,M3,M4)

     pred_null <- as.factor(rep(FALSE, length(pred_log)))
     levels(pred_null) = list("fail" = FALSE, "success" = TRUE)

     pred_simple <- predict( object = simple_m, newdata = train_te, type = "link")
     pred_simple <-  as.factor(pred_simple > 0.5)
     levels(pred_simple) = list("fail" = FALSE, "success" = TRUE)

     pred_random <- as.factor(runif(length(pred_log)) > 0.5 )
     levels(pred_random) = list("fail" = FALSE, "success" = TRUE)

     bool_log  <- pred_log == train_te$requester_received_pizza
     bool_gbm  <- pred_gbm == train_te$requester_received_pizza
     bool_rf   <- pred_rf == train_te$requester_received_pizza
     bool_nnet <- pred_nnet == train_te$requester_received_pizza
     ## bool_svm  <- pred_svm == train_te$requester_received_pizza
     bool_mean <- pred_mean == train_te$requester_received_pizza

     bool_null <- pred_null == train_te$requester_received_pizza
     bool_simple <- pred_simple == train_te$requester_received_pizza
     bool_random <- pred_random == train_te$requester_received_pizza

     r_df <- cbind( train_te[, ind_vars],
                   train_te$requester_received_pizza, bool_log,bool_gbm,
                   bool_rf, bool_nnet, bool_mean, bool_null, bool_random) ## bool_svm)

     confusionMatrix(pred_log, train_te$requester_received_pizza)
     confusionMatrix(pred_gbm, train_te$requester_received_pizza)
     confusionMatrix(pred_rf, train_te$requester_received_pizza)
     confusionMatrix(pred_nnet, train_te$requester_received_pizza)
     ##confusionMatrix(pred_svm, train_te$requester_received_pizza)

     confusionMatrix(pred_null, train_te$requester_received_pizza)
     confusionMatrix(pred_mean, train_te$requester_received_pizza)

     cor(r_df[,c("bool_log","bool_gbm","bool_rf","bool_nnet")])

    #+end_src
  
** Diagnostics
  
   Como adicionar alguma metrica mais simples como por exemplo
   precision or

   #+begin_src R
     ## compare models algorithms (legal esta metodo)
     resamps <- resamples(list(LOGIT = logit_m,
                               GBM = gbm_m,
                               RF  = rf_m,
                               NNET = nnet_m,
                               SVM = svm_m))

     summary(resamps)

     bwplot(resamps, layout = c(1, 3))
   #+end_src


   =================================

   Permutation test 

* Conclusion
